---
title: "hw-03"
author: "Your Name (S000000)"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
## **DO NOT EDIT THIS CODE CHUNK**
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
```


## Data Load and Preparation

```{r read_data}
gss16<-read.csv("data/gss16.csv")
```

Re-level the `advfront` variable such that it has two levels:

```{r}
gss16 <- gss16 %>%
  mutate(
    advfront = case_when(
      advfront %in% c("Agree", "Strongly agree") ~ "Agree",
      is.na(advfront) ~ NA_character_,
      TRUE ~ "Not agree"
    ),
    advfront = fct_relevel(advfront, "Not agree", "Agree")
  )

gss16 %>%
  count(advfront)

```

Combine the levels of the `polviews` variable (political views) such that levels that have the word "liberal" in them are lumped into a level called `"Liberal"` and those that have the word "conservative" in them are lumped into a level called `"Conservative"`. Then, re-order the levels in the following order: `"Conservative"` , `"Moderate"`, and `"Liberal"`

```{r}
gss16 <- gss16 %>%
  mutate(
    polviews = case_when(
      str_detect(polviews, "[Cc]onservative") ~ "Conservative",
      str_detect(polviews, "[Ll]iberal") ~ "Liberal",
      TRUE ~ polviews
    ),
    polviews = fct_relevel(polviews, "Conservative", "Moderate", "Liberal")
  )

gss16 %>%
  count(polviews)
```

Selecting and removing missing observations

```{r}
gss16_advfront <- gss16 %>%
  select(advfront, emailhr, educ, polviews, wrkstat) %>%
  drop_na()

gss16_advfront[1:10,]
```

## Exercise 1: Create a linear regression model

Consider the numerical values `educ` and `emailhr` from your new data set `gss16_advfront`.

a) Fit a linear regression model to predicting `emailhr` based on the `educ`. From your output, state the formula for the line-of-best fit and give an interpretation of the `emailhr` estimate.

b) Comment on the overall performance of the linear regression model. Support your statements with an appropriate data visualisation and model fit statistics.

```{r}

```

## Exercise 2: Create a workflow to fit a model

In this part, we're going to build a model to predict whether someone agrees or doesn't agree with the following statement:

Even if it brings no immediate benefits, scientific research that advances the frontiers of knowledge is necessary and should be supported by the federal government.

The responses to the question on the GSS about this statement are in the `advfront` variable, in the `gss16_advfront` data that you obtained.

First, use the following code to split the dataset into a training dataset (`gss16_train`) and a testing dataset (`gss16_test`). This code splits the data into 75\% training and 25\% testing.

```{r split-data, eval=FALSE}
set.seed(1234)
gss16_split <- initial_split(gss16_advfront)
gss16_train <- training(gss16_split)
gss16_test  <- testing(gss16_split)
```

a) Build a workflow for the training data that consists of a recipe (`gss16_rec_1`) and a model (`gss16_mod_1`). Name this workflow `gss16_wflow_1`.
    
The recipe (named `gss16_rec_1`) should contain the following steps for predicting `advfront` from `educ`:

  - `step_dummy()` to create dummy variables for `all_nominal()` variables that are predictors, i.e. not "outcomes". You can select outcomes using `all_outcomes()`

  - The model (named `gss16_mod_1`) should specify a model that is appropriate for the data as well as the computational engine.

```{r}

```

b) Explain why you have chosen the model that you have selected.

## Exercise 3: Logistic regression with single predictor

a) Apply the workflow you defined earlier to the training dataset and named the model as `gss16_fit_1`. Display the resulting tibble containing the fitted model parameters. 

```{r}

```

b) Use the fitted models to predict the test data, plot the ROC curves for the predictions.

```{r}

```

## Exercise 4: Logistic regression modelling and interpretation

We are now going to model `advfront` using the explanatory variables `polviews`, `wrkstat`, and `educ`.

a) Build a new workflow for the training data that consists of a recipe (`gss16_rec_2`) and a model (`gss16_mod_2`). Name this workflow `gss16_wflow_2`. You can simply **copy, paste and edit** the code from earlier.
    
Now the new recipe (named `gss16_rec_2`) should contain the followings for predicting `advfront` from `polviews`, `wrkstat`, and `educ`:

  - `step_dummy()` to create dummy variables for `all_nominal()` variables that are predictors, i.e. not "outcomes". You can select outcomes using `all_outcomes()`

  - The model (named `gss16_mod_2`) should specify a model that is appropriate for the data as well as the computational engine.
  
Apply the new workflow to the training dataset and create a new model fit 
named as `gss16_fit_2`. 

Then use the fitted models to predict the test data, plot the ROC curve for the predictions for both models, and calculate the areas under the ROC curves.

```{r}

```

b) Comment on which model performs better 

  * the model only including `educ`, as model 1 (`gss16_fit_1`) 
  * the model including `polviews`, `wrkstat`, and `educ` with `gss16_split` as model 2 (`gss16_fit_2`)
  
Explain your reasoning.

```{r}

```



