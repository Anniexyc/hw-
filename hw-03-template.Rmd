---
title: "hw-03"
author: "Your Name (S000000)"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
## **DO NOT EDIT THIS CODE CHUNK**
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
```


## Exercise 1: Prepare the dataset for modelling

```{marginfigure}
It's important that you don't recode the NAs, just the remaining levels.
```

Re-level the `advfront` variable such that it has two levels: `"Strongly agree"` and `"Agree"` combined into a new level called `"Agree"` and the remaining levels (except `NA`s) combined into `"Not agree"`. Make sure the levels are in the following order: `"Not agree"` and `"Agree"`. Finally, `count()` how many times each new level appears in the `advfront` variable. The following code does that job for this re-leveling

```{r}
gss16 <- gss16 %>%
  mutate(
    advfront = case_when(
      advfront %in% c("Agree", "Strongly agree") ~ "Agree",
      is.na(advfront) ~ NA_character_,
      TRUE ~ "Not agree"
    ),
    advfront = fct_relevel(advfront, "Not agree", "Agree")
  )

gss16 %>% head()
```


a)  Combine the levels of the `polviews` variable (political views) such that levels that have the word "liberal" in them are lumped into a level called `"Liberal"` and those that have the word "conservative" in them are lumped into a level called `"Conservative"`. Then, re-order the levels in the following order: `"Conservative"` , `"Moderate"`, and `"Liberal"`. Finally, `count()` how many times each new level appears in the `polviews` variable.

```{r}

```

b)  Create a new data frame called `gss16_advfront` that includes the variables `advfront`, `emailhr` (Number of hours spent on email weekly), `educ` (education level), `polviews` (political views), and `wrkstat` (working status).

Then, use the `drop_na()` function to remove rows that contain `NA`s from this new data frame. Print the top ten rows of your data frame.

```{r}

```

## Exercise 2: Create a linear regression model

Consider the numerical values from your new data set `gss16_advfront`, `educ` and `emailhr`.

a) Does it reasonable to fit a linear regression model for the relationship between `educ` and `emailhr`? Justify your reasoning briefly

b) When you fit a linear regression model to explain `emailhr` by using the `educ` as explanatory variable, what is the estimated model as a function and overall model performance

```{r}

```

## Exercise 3: Create a workflow to fit a model

In this part, we're going to build a model to predict whether someone agrees or doesn't agree with the following statement:

Even if it brings no immediate benefits, scientific research that advances the frontiers of knowledge is necessary and should be supported by the federal government.

The responses to the question on the GSS about this statement are in the `advfront` variable, in the `gss16_advfront` data that you obtained.

First, use the following code to split the dataset into a training dataset (`gss16_train`) and a testing dataset (`gss16_test`). This code splits the data into 75\% training and 25\% testing.

```{r split-data, eval=FALSE}
set.seed(1234)
gss16_split <- initial_split(gss16_advfront)
gss16_train <- training(gss16_split)
gss16_test  <- testing(gss16_split)
```

Build a workflow for the training data that consists of a recipe (`gss16_rec_1`) and a model (`gss16_spec_1`). Name this workflow `gss16_wflow_1`.
    
The recipe (named `gss16_rec_1`) should contain the following steps for predicting `advfront` from `polviews`, `wrkstat`, and `educ`:

    -   `step_other()` to pool values that occur less than 10% of the time in the `wrkstat` variable into `"Other"`.

    -   `step_dummy()` to create dummy variables for `all_nominal()` variables that are predictors, i.e. not "outcomes".
        You can select outcomes using `all_outcomes()`

The model (named `gss16_spec_1`) should specify a model that is appropriate for the data as well as the computational engine.

Explain why you have chosen the model that you have selected.

```{r}

```

## Exercise 4: Logistic regression modelling and interpretation

a)  Apply the workflow you defined earlier to the training dataset and display the resulting tibble containing the fitted model parameters. 

```{r}

```

b) Now, try a different, simpler model: predict `advfront` from only `polviews` and `educ`. Update your workflow and recipe to reflect this simpler model specification (and name the updated workflow `gss16_wflow_2`). 

- Apply both of your models to the training data using the two workflows that you have defined. Then use the fitted models to predict the test data, plot the ROC curves for the predictions for both models, and calculate the areas under the ROC curves.

```{r}

```

- Comment on which model performs better (the model including `wrkstat`, model 1, or the model excluding `wrkstat`, model 2). Explain your reasoning. 



